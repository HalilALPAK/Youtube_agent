import os
import cv2
import subprocess
import whisper
import numpy as np
from insightface.app import FaceAnalysis
from rapidfuzz import fuzz

# ====================== AYARLAR ======================
VIDEO_IN = "input.mp4"
VIDEO_OUT = "output_censored.mp4"
AUDIO_FILE = "audio.wav"
TRANSCRIPT_FILE = "transcript.txt"
LANG = "tr"
MODEL_PATH = "small"
THRESHOLD = 70
FILLERS = ["siktir", "orospu", "lan", "bok", "amk","oruspu Ã§ocuÄŸu","oros bu Ã§ocuÄŸu","yarrak","piÃ§","gÃ¶t","sik","amÄ±na koyim","amcÄ±k","sikiyim","yavÅŸak","pezevenk","kahpe","mal","salak","aptal","gerizekalÄ±"]

DEVICE = -1
MIN_FACE_SIZE = 50

# ====================== SES Ã‡IKAR ======================
print("ğŸ”Š Ses Ã§Ä±karÄ±lÄ±yor...")
subprocess.run([
    "ffmpeg", "-y",
    "-i", VIDEO_IN,
    "-ac", "1",
    "-ar", "16000",
    AUDIO_FILE
], check=True)

# ====================== TRANSKRÄ°PT ======================
print("ğŸ§  Whisper modeli yÃ¼kleniyor...")
model = whisper.load_model(MODEL_PATH)
result = model.transcribe(AUDIO_FILE, language=LANG, word_timestamps=True, fp16=False)

# ====================== TRANSKRÄ°PT DOSYAYA ======================
with open(TRANSCRIPT_FILE, "w", encoding="utf-8") as f:
    for seg in result["segments"]:
        f.write(f"[{seg['start']:.2f} - {seg['end']:.2f}] {seg['text']}\n")
print(f"ğŸ“ Transkript kaydedildi â†’ {TRANSCRIPT_FILE}")

# ====================== KÃœFÃœR SEGMENTLERÄ° ======================
curse_times = []
print("ğŸ” KÃ¼fÃ¼r tespiti baÅŸlÄ±yor...")
for seg in result["segments"]:
    text = seg["text"].lower()
    found = False
    for curse in FILLERS:
        score = fuzz.partial_ratio(text, curse)
        if score >= THRESHOLD:
            curse_times.append((seg["start"], seg["end"]))
            print(f"ğŸ’¢ KÃ¼fÃ¼r bulundu: '{curse}' in segment '{text}' | Benzerlik: {score}% | {seg['start']:.2f}-{seg['end']:.2f}s")
            found = True
            break
    if not found:
        print(f"âšª KÃ¼fÃ¼r yok: '{text}'")

if not curse_times:
    print("âš ï¸ KÃ¼fÃ¼r bulunamadÄ±!")

# ====================== FRAME LÄ°STESÄ° ======================
cap = cv2.VideoCapture(VIDEO_IN)
fps = cap.get(cv2.CAP_PROP_FPS)
w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fourcc = cv2.VideoWriter_fourcc(*"mp4v")
out = cv2.VideoWriter(VIDEO_OUT, fourcc, fps, (w, h))

curse_frames = set()
for start, end in curse_times:
    s_idx = int(start * fps)
    e_idx = int(end * fps)
    curse_frames.update(range(s_idx, e_idx + 1))

print(f"ğŸ’¢ {len(curse_frames)} frame kÃ¼fÃ¼r iÃ§eriyor, aÄŸÄ±z kutusu eklenecek...")

# ====================== FACE MODEL ======================
print("âš™ï¸ InsightFace yÃ¼kleniyor...")
app = FaceAnalysis(name="buffalo_l")
app.prepare(ctx_id=DEVICE, det_size=(640, 640))

# ====================== VIDEO Ä°ÅLE ======================
frame_idx = 0
while True:
    ret, frame = cap.read()
    if not ret:
        break

    if frame_idx in curse_frames:
        faces = app.get(frame)
        if not faces:
            print(f"âš ï¸ Frame {frame_idx} yÃ¼z bulunamadÄ±!")
        for face in faces:
            x1, y1, x2, y2 = map(int, face.bbox)
            if (x2 - x1) < MIN_FACE_SIZE:
                print(f"âš ï¸ Frame {frame_idx} yÃ¼z kÃ¼Ã§Ã¼k, atlandÄ±!")
                continue

            # Dudak landmark varsa normal Ã§izim
            if face.landmark is not None and len(face.landmark) >= 68:
                lips_x = face.landmark[48:68, 0].astype(int)
                lips_y = face.landmark[48:68, 1].astype(int)
                lx1, ly1 = lips_x.min(), lips_y.min()
                lx2, ly2 = lips_x.max(), lips_y.max()
            else:
                # Landmark yoksa yÃ¼z alt kÄ±smÄ±nÄ± kapat
                lx1 = x1
                lx2 = x2
                ly1 = int(y1 + (y2 - y1) * 0.6)
                ly2 = y2

            cv2.rectangle(frame, (lx1, ly1), (lx2, ly2), (0, 0, 0), -1)
            print(f"âœ… Frame {frame_idx} aÄŸÄ±z kapandÄ±: {lx1},{ly1}-{lx2},{ly2}")

    out.write(frame)
    frame_idx += 1

cap.release()
out.release()
print("âœ… Ã‡Ä±ktÄ± oluÅŸturuldu â†’", VIDEO_OUT)
